## Combining a CNN and a DNN and test if this performs better then
## the plain DNN


# Version 1:

  * Implement CNN and DNN as before and then merge them after sone dense/Conv2D
    layers. Then train some dense layers together
    --> The performance does not get better.
    (Best structure yet:
        modelCNN = models.Sequential()
        modelCNN.add(Conv2D(32, (4, 4), padding="same", input_shape = self.data.size_input_image))
        modelCNN.add(Activation("relu"))
        modelCNN.add(AveragePooling2D(pool_size=(2,2)))
        modelCNN.add(Conv2D(64, (4, 4), padding="same"))
        modelCNN.add(Activation("relu"))
        modelCNN.add(AveragePooling2D(pool_size=(2, 2)))
        modelCNN.add(Conv2D(128, (4, 4), padding="same"))
        modelCNN.add(Activation("relu"))
        modelCNN.add(AveragePooling2D(pool_size=(2, 2)))
        modelCNN.add(Flatten())

        modelDNN = models.Sequential()
        modelDNN.add(Dense(100, input_shape = (self.data.n_input_neurons,)))
        modelDNN.add(Activation("relu"))
        modelDNN.add(Dropout(0.5))
        modelDNN.add(Dense(100))
        modelDNN.add(Activation("relu"))
        modelDNN.add(Dropout(0.5))

        mergedOutput = layer.Concatenate()([modelCNN.output, modelDNN.output])
        out = Dense(100, activation='relu')(mergedOutput)
        out = Dropout(0.5)(out)
        out = Dense(100, activation='relu')(out)
        out = Dense(self.data.n_output_neurons, activation='softmax')(out)
        mergedModel = models.Model([modelCNN.input, modelDNN.input], out))
    )

# Version 2:
